{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depression in Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/benthompson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/benthompson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import nltk library\n",
    "import nltk; nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "# import stopword libraries\n",
    "nltk.download('stopwords'); from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "# import other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# import word embedding library\n",
    "#import glove_helper\n",
    "\n",
    "# import helper libraries\n",
    "import collections\n",
    "from common import utils, vocabulary\n",
    "\n",
    "#display multiple results per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#export models\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in tweets\n",
    "df = pd.DataFrame.from_csv('../depression_subreddit_nondeleted_201801_06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add index\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was on 20mg fluoxetine for a while and it di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wonderful. You are the poet amongst fools, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;gt;Women dont like depressed n***ers \\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whoosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I definitely hear this. I'm sorry you're feeli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  I was on 20mg fluoxetine for a while and it di...\n",
       "1  Wonderful. You are the poet amongst fools, you...\n",
       "2  &gt;Women dont like depressed n***ers \\n\\n\\n\\n...\n",
       "3                                            Whoosh \n",
       "4  I definitely hear this. I'm sorry you're feeli..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311132"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how man non-distinct tweets\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create column on 1's\n",
    "x = [1]\n",
    "x = x * len(df)\n",
    "df['target'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make all lowercase\n",
    "df['body'] = df['body'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was on 20mg fluoxetine for a while and it di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful. you are the poet amongst fools, you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;gt;women dont like depressed n***ers \\n\\n\\n\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whoosh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i definitely hear this. i'm sorry you're feeli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  target\n",
       "0  i was on 20mg fluoxetine for a while and it di...       1\n",
       "1  wonderful. you are the poet amongst fools, you...       1\n",
       "2  &gt;women dont like depressed n***ers \\n\\n\\n\\n...       1\n",
       "3                                            whoosh        1\n",
       "4  i definitely hear this. i'm sorry you're feeli...       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in random tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in tweets\n",
    "df_2 = pd.DataFrame.from_csv('../random_tweets.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True but she still cancelled tho.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RT @roxxxdoxxx: when she said \"i gotta ask first\" i felt that ðŸ˜«ðŸ˜…ðŸ˜‚ https://t.co/BGPZqFLb9v</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appreciate this perfectly timed pic of me and catto pls https://t.co/GE5poooRcF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one of BeyoncÃ©â€™s most underrated looks is the one from Jealous. donâ€™t @ me</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"Once you create a system for censoring speech on the grounds that it is 'fake news' (even if it's parody, or sarcaâ€¦ https://t.co/EpuSUaK0UC</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [True but she still cancelled tho., RT @roxxxdoxxx: when she said \"i gotta ask first\" i felt that ðŸ˜«ðŸ˜…ðŸ˜‚ https://t.co/BGPZqFLb9v, appreciate this perfectly timed pic of me and catto pls https://t.co/GE5poooRcF, one of BeyoncÃ©â€™s most underrated looks is the one from Jealous. donâ€™t @ me, \"Once you create a system for censoring speech on the grounds that it is 'fake news' (even if it's parody, or sarcaâ€¦ https://t.co/EpuSUaK0UC]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at data\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135177"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many\n",
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#give index\n",
    "df_2 = df_2.reset_index()\n",
    "\n",
    "#give column name\n",
    "df_2.columns = ['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111985"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many distinct tweets\n",
    "len(df_2.body.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dataframe of unique\n",
    "df_2 = pd.DataFrame(df_2.body.unique())\n",
    "\n",
    "#give column name\n",
    "df_2.columns = ['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make all tweets lowercase\n",
    "df_2['body'] = df_2['body'].str.lower()\n",
    "df_2.columns = ['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true but she still cancelled tho.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @roxxxdoxxx: when she said \"i gotta ask fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appreciate this perfectly timed pic of me and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one of beyoncÃ©â€™s most underrated looks is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"once you create a system for censoring speech...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0                  true but she still cancelled tho.\n",
       "1  rt @roxxxdoxxx: when she said \"i gotta ask fir...\n",
       "2  appreciate this perfectly timed pic of me and ...\n",
       "3  one of beyoncÃ©â€™s most underrated looks is the ...\n",
       "4  \"once you create a system for censoring speech..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>rt @nickhansonmn: hey sorry iâ€™ve been distant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>rt @matrix_reioaded: ahh iâ€™m depressed... but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>rt @caucasianjames: on tinder depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>rt @softyoonle: hi this would really help me a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>rt @iamsofiadg: philippines ðŸ‡µðŸ‡­ \\nneed someone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>rt @depressionnote: warning signs of depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>rt @fuxksalliemae: alot of nigerians are strug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>rt @daitonreed: you do not have to come this h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>rt @sionesnow: when i read the first sentence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>i can't help the fact that i make all my chara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>rt @prince_madness1: know the signs of depress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6907</th>\n",
       "      <td>rt @depresseddarth: the dark side of the moon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>rt @kanyepodcast: @kanyewest unfortunately, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>@lin_manuel man i wish. sometimes i feel like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>rt @imtheebrock: me 5 minutes after being depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10191</th>\n",
       "      <td>kids who still exist from elementary have depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10595</th>\n",
       "      <td>iâ€™m fucking depressed i had to pass up on beyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>letâ€™s talk about how i was so depressed that i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13416</th>\n",
       "      <td>â€¢ fights oxidative stress in the body\\nâ€¢ may c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>rt @bimtrimmer: rt if u\\n\\n- broke\\n- want con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>rt @depresseddarth: when it's friday night but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>rt @_kelliraee_: this is what defeating depres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14563</th>\n",
       "      <td>rt @sopetacles: hello! my name is jyn and iâ€™m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>rt @depresseddarth: when it's friday night but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15611</th>\n",
       "      <td>rt @wearegraves: i canâ€™t wait to start releasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17008</th>\n",
       "      <td>hey... so thank you @bryandechart for just hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18377</th>\n",
       "      <td>rt @depresseddarth: â€œhello elon, can you pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18978</th>\n",
       "      <td>rt @baba_fatymah: @ayshaummy4 @zikirillahi all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20281</th>\n",
       "      <td>rt @youthkiawaaz: let's talk about depression....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23597</th>\n",
       "      <td>been unhappy and depressed for so long i don't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91929</th>\n",
       "      <td>iâ€™m high key depressed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92002</th>\n",
       "      <td>rt @depressionnote: today i feel\\n\\nâ€¢ abandone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92107</th>\n",
       "      <td>rt @depressionnote: it doesnâ€™t matter what rac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92576</th>\n",
       "      <td>rt @camhnews: 'kate spadeâ€™s death proves depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92584</th>\n",
       "      <td>rt @stevenspohn: the most successful people i'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92904</th>\n",
       "      <td>rt @itsrjhill: iâ€™m so depressed yo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93164</th>\n",
       "      <td>rt @nikkilipstick: âœ¨ðŸ–¤ðŸŽ€when you finally get a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93698</th>\n",
       "      <td>@freshempire how come there's not a depressed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94878</th>\n",
       "      <td>i feel like i just hit straight random depress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94982</th>\n",
       "      <td>rt @v_nooguyen: one of my professors wrote a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96304</th>\n",
       "      <td>rt @supremeshana_: religion doesn't cure depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96340</th>\n",
       "      <td>rt @drgnkiller: i like how he starts with â€œiâ€™m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97603</th>\n",
       "      <td>rt @a_joseph1616: \"thanks to psychedelic drugs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97894</th>\n",
       "      <td>the intensity of my depression tends to strike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98085</th>\n",
       "      <td>rt @sidayaofficial: causes of insomnia: \\n\\nre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100539</th>\n",
       "      <td>rt @sierracheyanne_: i hope this shit makes me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101869</th>\n",
       "      <td>rt @athariyyah_: it's actually bare upsetting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103044</th>\n",
       "      <td>rt @tonysraptorsofc: i wish there was one day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103322</th>\n",
       "      <td>rt @leelamad: @nazeeahmed no run means i am de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105468</th>\n",
       "      <td>off work finally yes now time to go home and l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105472</th>\n",
       "      <td>rt @asapyams: very depressed writing in lower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106295</th>\n",
       "      <td>@19chelsea94 i quit my job recently to focus o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106921</th>\n",
       "      <td>thatâ€™s called depression lol https://t.co/fhmu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107568</th>\n",
       "      <td>rt @spacebrat: its funny how u get depressed a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107822</th>\n",
       "      <td>rt @itzwikipedia: too much homework can cause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108714</th>\n",
       "      <td>iâ€™m so tired of being a worthless piece of shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109421</th>\n",
       "      <td>trump's america wants to get rid of coverage f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110060</th>\n",
       "      <td>rt @rosyfuck: @bbzaria @aljaminbrydie omg did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110185</th>\n",
       "      <td>this is for those, who are sad, frustrated, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111439</th>\n",
       "      <td>shoutout to being depressed and malnourished f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body\n",
       "1769    rt @nickhansonmn: hey sorry iâ€™ve been distant ...\n",
       "1918    rt @matrix_reioaded: ahh iâ€™m depressed... but ...\n",
       "2568              rt @caucasianjames: on tinder depressed\n",
       "2763    rt @softyoonle: hi this would really help me a...\n",
       "3507    rt @iamsofiadg: philippines ðŸ‡µðŸ‡­ \\nneed someone ...\n",
       "4159    rt @depressionnote: warning signs of depressio...\n",
       "4268    rt @fuxksalliemae: alot of nigerians are strug...\n",
       "4547    rt @daitonreed: you do not have to come this h...\n",
       "5501    rt @sionesnow: when i read the first sentence ...\n",
       "6143    i can't help the fact that i make all my chara...\n",
       "6601    rt @prince_madness1: know the signs of depress...\n",
       "6907    rt @depresseddarth: the dark side of the moon ...\n",
       "8795    rt @kanyepodcast: @kanyewest unfortunately, it...\n",
       "8978    @lin_manuel man i wish. sometimes i feel like ...\n",
       "8983    rt @imtheebrock: me 5 minutes after being depr...\n",
       "10191   kids who still exist from elementary have depr...\n",
       "10595   iâ€™m fucking depressed i had to pass up on beyo...\n",
       "11851   letâ€™s talk about how i was so depressed that i...\n",
       "13416   â€¢ fights oxidative stress in the body\\nâ€¢ may c...\n",
       "13514   rt @bimtrimmer: rt if u\\n\\n- broke\\n- want con...\n",
       "13878   rt @depresseddarth: when it's friday night but...\n",
       "14291   rt @_kelliraee_: this is what defeating depres...\n",
       "14563   rt @sopetacles: hello! my name is jyn and iâ€™m ...\n",
       "14996   rt @depresseddarth: when it's friday night but...\n",
       "15611   rt @wearegraves: i canâ€™t wait to start releasi...\n",
       "17008   hey... so thank you @bryandechart for just hel...\n",
       "18377   rt @depresseddarth: â€œhello elon, can you pleas...\n",
       "18978   rt @baba_fatymah: @ayshaummy4 @zikirillahi all...\n",
       "20281   rt @youthkiawaaz: let's talk about depression....\n",
       "23597   been unhappy and depressed for so long i don't...\n",
       "...                                                   ...\n",
       "91929                             iâ€™m high key depressed.\n",
       "92002   rt @depressionnote: today i feel\\n\\nâ€¢ abandone...\n",
       "92107   rt @depressionnote: it doesnâ€™t matter what rac...\n",
       "92576   rt @camhnews: 'kate spadeâ€™s death proves depre...\n",
       "92584   rt @stevenspohn: the most successful people i'...\n",
       "92904                  rt @itsrjhill: iâ€™m so depressed yo\n",
       "93164   rt @nikkilipstick: âœ¨ðŸ–¤ðŸŽ€when you finally get a h...\n",
       "93698   @freshempire how come there's not a depressed ...\n",
       "94878   i feel like i just hit straight random depress...\n",
       "94982   rt @v_nooguyen: one of my professors wrote a t...\n",
       "96304   rt @supremeshana_: religion doesn't cure depre...\n",
       "96340   rt @drgnkiller: i like how he starts with â€œiâ€™m...\n",
       "97603   rt @a_joseph1616: \"thanks to psychedelic drugs...\n",
       "97894   the intensity of my depression tends to strike...\n",
       "98085   rt @sidayaofficial: causes of insomnia: \\n\\nre...\n",
       "100539  rt @sierracheyanne_: i hope this shit makes me...\n",
       "101869  rt @athariyyah_: it's actually bare upsetting ...\n",
       "103044  rt @tonysraptorsofc: i wish there was one day ...\n",
       "103322  rt @leelamad: @nazeeahmed no run means i am de...\n",
       "105468  off work finally yes now time to go home and l...\n",
       "105472  rt @asapyams: very depressed writing in lower ...\n",
       "106295  @19chelsea94 i quit my job recently to focus o...\n",
       "106921  thatâ€™s called depression lol https://t.co/fhmu...\n",
       "107568  rt @spacebrat: its funny how u get depressed a...\n",
       "107822  rt @itzwikipedia: too much homework can cause ...\n",
       "108714  iâ€™m so tired of being a worthless piece of shi...\n",
       "109421  trump's america wants to get rid of coverage f...\n",
       "110060  rt @rosyfuck: @bbzaria @aljaminbrydie omg did ...\n",
       "110185  this is for those, who are sad, frustrated, al...\n",
       "111439  shoutout to being depressed and malnourished f...\n",
       "\n",
       "[138 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for tweets that use depression\n",
    "df_2[(df_2['body'].str.contains('depressed') | df_2['body'].str.contains('depression'))]\n",
    "\n",
    "#drop them\n",
    "df_2.drop(df_2[(df_2.body.str.contains('depressed')) | (df_2.body.str.contains('depression'))].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111847"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recheck length\n",
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export to check quality\n",
    "# df_2_sample = df_2.sample(n=100)\n",
    "# df_2_sample.to_csv('../sample_100_random_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#column of 0's\n",
    "x = 0\n",
    "x = x * len(df_2)\n",
    "\n",
    "df_2['target'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#balance classes\n",
    "df_3 = df.sample(n=len(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine dfs\n",
    "df = pd.concat([df_3,df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223694"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60649</th>\n",
       "      <td>yeah this is something i struggle with all the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127446</th>\n",
       "      <td>being on the reverse, the thing i want more th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127017</th>\n",
       "      <td>know how it feels man. for the past 4 months i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88863</th>\n",
       "      <td>i have a genetic condition of gaining weight. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125979</th>\n",
       "      <td>i am over it nigga iâ€™m at the gym keep it moving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body  target\n",
       "60649   yeah this is something i struggle with all the...       1\n",
       "127446  being on the reverse, the thing i want more th...       1\n",
       "127017  know how it feels man. for the past 4 months i...       1\n",
       "88863   i have a genetic condition of gaining weight. ...       1\n",
       "125979  i am over it nigga iâ€™m at the gym keep it moving        1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rt @ techreview : a neural network can detect depression and mania in bipolar subjects by analyzing how they hold and tap on their smartphoneâ€¦ '\n"
     ]
    }
   ],
   "source": [
    "#preprocess tweets\n",
    "example_text=\"\"\"'RT @techreview: A neural network can \n",
    "detect depression and mania in bipolar subjects \n",
    "by analyzing how they hold and tap on their smartphoneâ€¦'\"\"\"\n",
    "\n",
    "# tokenize\n",
    "def tokenize_text(input_text):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "    input_text: a string representing an \n",
    "    individual review\n",
    "        \n",
    "    Returns:\n",
    "    input_token: a list containing stemmed \n",
    "    tokens, with punctutations removed, for \n",
    "    an individual review\n",
    "        \n",
    "    \"\"\"\n",
    "    input_tokens=[]\n",
    "        \n",
    "    # Split sentence\n",
    "    sents=sent_tokenize(input_text)\n",
    "            \n",
    "    # Split word\n",
    "    for sent in sents:\n",
    "        input_tokens+=TreebankWordTokenizer().tokenize(sent)\n",
    "        \n",
    "    return input_tokens\n",
    "\n",
    "\n",
    "# canonicalize\n",
    "def canonicalize_tokens(input_tokens):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    input_tokens: a list containing tokenized \n",
    "    tokens for an individual review\n",
    "    \n",
    "    Returns:\n",
    "    input_tokens: a list containing canonicalized \n",
    "    tokens for an individual review\n",
    "    \n",
    "    \"\"\"\n",
    "    input_tokens=utils.canonicalize_words(input_tokens)\n",
    "    return input_tokens\n",
    "\n",
    "\n",
    "# preprocessor \n",
    "def preprocessor(raw_text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    raw_text: a string representing an\n",
    "    individual review\n",
    "    \n",
    "    Returns:\n",
    "    preprocessed_text: a string representing \n",
    "    a preprocessed individual review\n",
    "    \n",
    "    \"\"\"\n",
    "    # tokenize\n",
    "    tokens=tokenize_text(raw_text)\n",
    "    \n",
    "    # canonicalize\n",
    "    canonical_tokens=canonicalize_tokens(tokens)\n",
    "    \n",
    "    # rejoin string\n",
    "    preprocessed_text=(\" \").join(canonical_tokens) \n",
    "    return preprocessed_text\n",
    "\n",
    "# example data\n",
    "#input_tokens=tokenize_text(example_text)\n",
    "#print(input_tokens)\n",
    "\n",
    "#canonical_tokens=canonicalize_tokens(input_tokens)\n",
    "#print(canonical_tokens)\n",
    "\n",
    "preprocessed_text=preprocessor(example_text) \n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sklearn stopwords: 318\n",
      "number of nltk stopwords: 179\n",
      "number of total stopwords: 388\n"
     ]
    }
   ],
   "source": [
    "# examine stopwords\n",
    "\n",
    "# sklearn stopwords (frozenset)\n",
    "sklearn_stopwords=stop_words.ENGLISH_STOP_WORDS\n",
    "print(\"number of sklearn stopwords: %d\" %(len(sklearn_stopwords)))\n",
    "#print(sklearn_stopwords)\n",
    "\n",
    "# nltk stopwords (list)\n",
    "nltk_stopwords=stopwords.words(\"english\")\n",
    "print(\"number of nltk stopwords: %d\" %(len(nltk_stopwords)))\n",
    "#print(nltk_stopwords)\n",
    "\n",
    "# combined sklearn, nltk, other stopwords (set)\n",
    "total_stopwords=set(list(sklearn_stopwords.difference(set(nltk_stopwords)))+nltk_stopwords)\n",
    "\n",
    "other_stopwords=[\"DG\", \"DGDG\", \"@\", \"rt\", \"'rt\", \"'\", \":\", \"depression\", \"depressed\", \"RT\"]\n",
    "for w in other_stopwords:\n",
    "    total_stopwords.add(w)\n",
    "    \n",
    "print(\"number of total stopwords: %d\" %(len(total_stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['techreview', 'neural', 'network', 'detect', 'mania', 'bipolar', 'subjects', 'analyzing', 'hold', 'tap', 'smartphoneâ€¦']\n"
     ]
    }
   ],
   "source": [
    "#look at review w/o stop words\n",
    "new_review = []\n",
    "for i in preprocessed_text.split():\n",
    "    if i in total_stopwords:\n",
    "        continue\n",
    "    else:\n",
    "        new_review.append(i)\n",
    "        \n",
    "print(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, test set size: 178567, 45127\n",
      "\n",
      "example:\n",
      "body: yes i literally want to vanish to another world at this point. i feel like everything is pointless, like i want to be productive person but at the end of the day for what? i don't care. \n",
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "#split into test, train before sampling to belance\n",
    "# using recoded labels\n",
    "#create train, test data\n",
    "df['is_train'] = np.random.uniform(0,1, len(df)) <= .8\n",
    "\n",
    "train_data, test_data = df[df['is_train'] == True], df[df['is_train'] == False]\n",
    "\n",
    "# examine train, test shapes\n",
    "print(\"train, test set size: %d, %d\" %(len(train_data), len(test_data)))\n",
    "print(\"\")\n",
    "\n",
    "# examine train set examples\n",
    "print(\"example:\")\n",
    "print(\"body: %s\" %(train_data.get_value(10,'body')))\n",
    "print(\"label: %s\" %(train_data.get_value(10,'target')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    89332\n",
       "1    89235\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check class balance\n",
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example:\n",
      "body: it was consensual he asked first\n",
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"example:\")\n",
    "print(\"body: %s\" %(train_data.get_value(32,'body')))\n",
    "print(\"label: %s\" %(train_data.get_value(32,'target')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build tf-idf model\n",
    "vec=TfidfVectorizer(preprocessor=preprocessor, ngram_range=(1,3), stop_words=total_stopwords, max_features=10000)\n",
    "vec_train_data=vec.fit_transform(train_data['body']) \n",
    "vec_test_data=vec.transform(test_data['body']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression f1 score: 0.896\n",
      "logistic regression accuracy score: 0.896\n",
      "logistic regression confusion matrix:\n",
      "[[19983  2532]\n",
      " [ 2155 20457]]\n"
     ]
    }
   ],
   "source": [
    "# train Logistic Regression\n",
    "logit=LogisticRegression(penalty='l2')\n",
    "logit.fit(vec_train_data, train_data['target'])\n",
    "pred_labels=logit.predict(vec_test_data)\n",
    "    \n",
    "# assess model\n",
    "f1=f1_score(test_data['target'], pred_labels, average=\"weighted\") \n",
    "accuracy=accuracy_score(test_data['target'], pred_labels)\n",
    "confusion=confusion_matrix(test_data['target'], pred_labels)\n",
    "print(\"logistic regression f1 score: %.3f\" %(f1))\n",
    "print(\"logistic regression accuracy score: %.3f\" %(accuracy))\n",
    "print(\"logistic regression confusion matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try Keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create integer encoding of docs\n",
    "vocab_size = 100\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in df['tweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try tokenizer instead\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(df['tweets'])\n",
    "vocab_t_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create sequence\n",
    "encoded_t_docs = t.texts_to_sequences(df['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad docs to equals size\n",
    "pad = 40\n",
    "# padded_docs = pad_sequences(encoded_docs, maxlen=pad, padding='post')\n",
    "padded_t_docs = pad_sequences(encoded_t_docs, maxlen=pad, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85,  8, 87,  8, 14, 82, 55, 28, 34, 27, 27, 92, 81, 55, 62, 34, 30,\n",
       "       11, 73, 47, 90, 56, 53, 82,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs[11105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,Y_train,Y_test = train_test_split(padded_docs, df['target'], test_size=.8)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(padded_t_docs, df['target'], test_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44738, 40)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 40, 32)            11611520  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               320250    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 11,932,021\n",
      "Trainable params: 11,932,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Embedding(vocab_size, embedding_size, input_length=pad))\n",
    "model.add(Embedding(vocab_t_size, embedding_size, input_length=pad))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35790 samples, validate on 8948 samples\n",
      "Epoch 1/3\n",
      "35790/35790 [==============================] - 45s 1ms/step - loss: 0.3004 - acc: 0.8578 - val_loss: 0.1765 - val_acc: 0.9312\n",
      "Epoch 2/3\n",
      " 9344/35790 [======>.......................] - ETA: 30s - loss: 0.0603 - acc: 0.9807"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-6b9f2a15d4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.2)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benthompson/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "epochs=3\n",
    "batch_size=128\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_journal = [\"Sometime I feel very alone and anxious\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_journal = t.texts_to_sequences(keras_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5874, 8, 85, 163, 332, 9, 2197]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pad\n",
    "pad = 40\n",
    "padded_journal = pad_sequences(encoded_journal, maxlen=pad, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5874,    8,   85,  163,  332,    9, 2197,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "ynew = model.predict_proba(padded_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44699621]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights of words that predict depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>medication</th>\n",
       "      <td>4.153974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>4.159002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relate</th>\n",
       "      <td>4.308234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicidal</th>\n",
       "      <td>4.335760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video games</th>\n",
       "      <td>4.342867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helped</th>\n",
       "      <td>4.386488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>4.563139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anxiety</th>\n",
       "      <td>4.563813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meds</th>\n",
       "      <td>4.659559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>4.991141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op</th>\n",
       "      <td>5.049681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapy</th>\n",
       "      <td>5.190717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>try</th>\n",
       "      <td>5.203462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https www</th>\n",
       "      <td>5.217707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>5.287493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helps</th>\n",
       "      <td>5.622728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide</th>\n",
       "      <td>5.636972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapist</th>\n",
       "      <td>5.953323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>6.405812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>6.458078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Weights of words that predict depression\n",
       "medication                                   4.153974\n",
       "advice                                       4.159002\n",
       "relate                                       4.308234\n",
       "suicidal                                     4.335760\n",
       "video games                                  4.342867\n",
       "helped                                       4.386488\n",
       "normal                                       4.563139\n",
       "anxiety                                      4.563813\n",
       "meds                                         4.659559\n",
       "www                                          4.991141\n",
       "op                                           5.049681\n",
       "therapy                                      5.190717\n",
       "try                                          5.203462\n",
       "https www                                    5.217707\n",
       "com                                          5.287493\n",
       "helps                                        5.622728\n",
       "suicide                                      5.636972\n",
       "therapist                                    5.953323\n",
       "feel                                         6.405812\n",
       "reddit                                       6.458078"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get top words\n",
    "#look at top 5 weights for each class\n",
    "#get coefficients for all features\n",
    "coef_sq = logit.coef_\n",
    "\n",
    "#get index of top 5 absolute values for each class\n",
    "weight_indx = np.argsort(coef_sq)[:, -20:]\n",
    "\n",
    "#flatten so can use to look up wieghts\n",
    "weight_indx = weight_indx.flatten()\n",
    "\n",
    "#get coefficients based on index\n",
    "weights = coef_sq[:, weight_indx]\n",
    " \n",
    "#get words that match weights based on index\n",
    "vocab = np.array(vec.get_feature_names())[weight_indx]\n",
    "\n",
    "# make table\n",
    "df = pd.DataFrame({'Weights of words that predict depression': weights[0]}\n",
    "                  , index=vocab)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of class 0 and 1:  [[ 0.12156455  0.87843545]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights of words in sample Journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>-1.311699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure going</th>\n",
       "      <td>-0.339758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store</th>\n",
       "      <td>-0.043489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cashier</th>\n",
       "      <td>0.342796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>0.557809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strange</th>\n",
       "      <td>1.119725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weird</th>\n",
       "      <td>1.138772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>1.249253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makes feel</th>\n",
       "      <td>1.514279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>1.587885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makes</th>\n",
       "      <td>1.911366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>2.382613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>6.405812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Weights of words in sample Journal\n",
       "today                                 -1.311699\n",
       "sure going                            -0.339758\n",
       "store                                 -0.043489\n",
       "cashier                                0.342796\n",
       "wonderful                              0.557809\n",
       "strange                                1.119725\n",
       "weird                                  1.138772\n",
       "going                                  1.249253\n",
       "makes feel                             1.514279\n",
       "interaction                            1.587885\n",
       "makes                                  1.911366\n",
       "sure                                   2.382613\n",
       "feel                                   6.405812"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try to make up an example journal\n",
    "journal = \"\"\"Today was wonderful. I had a strange interaction at the store. \n",
    "The cashier seemed irratated. I'm not sure what's going on but it makes me feel weird\"\"\"\n",
    "\n",
    "#score test journal\n",
    "vec_test_example=vec.transform([journal]) \n",
    "print(\"probability of class 0 and 1: \",logit.predict_proba(vec_test_example))\n",
    "\n",
    "#get words and weights from test journal\n",
    "word_idx = np.nonzero(vec_test_example)[1]\n",
    "vocab = np.array(vec.get_feature_names())[word_idx]\n",
    "weights = coef_sq[:, word_idx]\n",
    "df = pd.DataFrame({'Weights of words in sample Journal': weights[0]}\n",
    "                  , index=vocab)\n",
    "df.sort_values(by='Weights of words in sample Journal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_exported_model']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export tfidf model\n",
    "tfidf_file = 'tfidf_exported_model'\n",
    "joblib.dump(vec, tfidf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export logistic regression\n",
    "logistic_regression_file = 'logistic_regression_model'\n",
    "joblib.dump(logit, logistic_regression_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of class 0 and 1:  [[ 0.43736519  0.56263481]]\n"
     ]
    }
   ],
   "source": [
    "#test out exported models against prev sample journal\n",
    "loaded_tfidf = joblib.load('tfidf_exported_model')\n",
    "loaded_lr = joblib.load('logistic_regression_model')\n",
    "\n",
    "#score test journal\n",
    "export_test_example=loaded_tfidf.transform([journal]) \n",
    "print(\"probability of class 0 and 1: \",loaded_lr.predict_proba(export_test_example))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras and Tensor Flow",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
