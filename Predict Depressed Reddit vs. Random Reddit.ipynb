{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depression in Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/benthompson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/benthompson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import nltk library\n",
    "import nltk; nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "# import stopword libraries\n",
    "nltk.download('stopwords'); from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "# import other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# import word embedding library\n",
    "#import glove_helper\n",
    "\n",
    "# import helper libraries\n",
    "import collections\n",
    "from common import utils, vocabulary\n",
    "\n",
    "#display multiple results per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#export models\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in reddit comments\n",
    "df = pd.read_csv('../depression_subreddit_nondeleted_201801_06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was on 20mg fluoxetine for a while and it di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wonderful. You are the poet amongst fools, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;gt;Women dont like depressed n***ers \\n\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whoosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I definitely hear this. I'm sorry you're feeli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  I was on 20mg fluoxetine for a while and it di...\n",
       "1  Wonderful. You are the poet amongst fools, you...\n",
       "2  &gt;Women dont like depressed n***ers \\n\\n\\n\\n...\n",
       "3                                            Whoosh \n",
       "4  I definitely hear this. I'm sorry you're feeli..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311132"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many non-distinct comments\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create column on 1's\n",
    "x = [1]\n",
    "x = x * len(df)\n",
    "df['target'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make all lowercase\n",
    "df['body'] = df['body'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was on 20mg fluoxetine for a while and it di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful. you are the poet amongst fools, you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;gt;women dont like depressed n***ers \\n\\n\\n\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whoosh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i definitely hear this. i'm sorry you're feeli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  target\n",
       "0  i was on 20mg fluoxetine for a while and it di...       1\n",
       "1  wonderful. you are the poet amongst fools, you...       1\n",
       "2  &gt;women dont like depressed n***ers \\n\\n\\n\\n...       1\n",
       "3                                            whoosh        1\n",
       "4  i definitely hear this. i'm sorry you're feeli...       1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in random Reddit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in random comments\n",
    "df_2 = pd.read_csv('../random_comments_20181011', usecols=[0], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashamed to say I expected two girls here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrested not prison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0\n",
       "0                                         body\n",
       "1                                    [removed]\n",
       "2                                        Pussy\n",
       "3  Ashamed to say I expected two girls here...\n",
       "4                         Arrested not prison "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at data\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668065"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many\n",
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#give column a name\n",
    "df_2.columns = ['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614809"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many distinct comments\n",
    "len(df_2.body.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make dataframe of unique\n",
    "df_2 = pd.DataFrame(df_2.body.unique())\n",
    "\n",
    "#give column name\n",
    "df_2.columns = ['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make all comments lowercase\n",
    "df_2['body'] = df_2['body'].str.lower()\n",
    "df_2.columns = ['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashamed to say i expected two girls here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrested not prison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          body\n",
       "0                                         body\n",
       "1                                    [removed]\n",
       "2                                        pussy\n",
       "3  ashamed to say i expected two girls here...\n",
       "4                         arrested not prison "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399697</th>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494744</th>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             body\n",
       "1       [removed]\n",
       "399697  [removed]\n",
       "494744  [removed]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many a [removed]\n",
    "df_2[df_2['body'] == '[removed]']\n",
    "\n",
    "#drop those 3\n",
    "df_2.drop(df_2[df_2['body'] == '[removed]'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove nans\n",
    "df_2.dropna(inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>your tears will be fun on election night. i ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>not op, but not everyone can work full time. w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>it feels like plastic but it could be impeccab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>you're being much more civil than i thought yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>i've never gotten so depressed so quickly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>please, explain those reasons. i'm sure they'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>she became extremely depressed upon entering t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8289</th>\n",
       "      <td>you can't easily make a gun in your house. dru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>&amp;gt; the unfriending left rachael feeling depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11036</th>\n",
       "      <td>well, depression is a mental disorder, so yes....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>are you fucking retarded?? your telling someon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12688</th>\n",
       "      <td>i think i want to stay away from stuff like su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13104</th>\n",
       "      <td>mine started so early i can't actually remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13138</th>\n",
       "      <td>i am not sure what exactly do you mean by depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14255</th>\n",
       "      <td>good thing it was anger that was the emotion h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14811</th>\n",
       "      <td>&amp;gt; treat depression and mental illness\\n\\n&amp;g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>most of the time i just wait until i stop feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15940</th>\n",
       "      <td>i loved reading about you two's so's and lives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16518</th>\n",
       "      <td>i have generalised anxiety disorder with some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16825</th>\n",
       "      <td>same thing goes about xmas.  i love the holida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17065</th>\n",
       "      <td>crippling depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17314</th>\n",
       "      <td>that, on a level, we *know* there isn't anythi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17575</th>\n",
       "      <td>i've had a week of vacation so i've been brows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17927</th>\n",
       "      <td>she didn't know i was struggling with depressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17991</th>\n",
       "      <td>i don't know how or why this got gilded, but i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18118</th>\n",
       "      <td>before: be sensual and flirty, not diving for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18214</th>\n",
       "      <td>i make a lot of money. i know it sounds douche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18996</th>\n",
       "      <td>this is basically me. i'm not sure, i might ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19110</th>\n",
       "      <td>as someone who keeps attempting it with clinic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19856</th>\n",
       "      <td>not at all! i appreciate the questions. i've b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567914</th>\n",
       "      <td>you need to make a plan before you do lose you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567920</th>\n",
       "      <td>no being mean but..... i think you may need so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570169</th>\n",
       "      <td>a potentially very valuable asian american roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570491</th>\n",
       "      <td>so testosterone depressed iq? maybe this shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573182</th>\n",
       "      <td>i must say that i'm glad about this. started h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580014</th>\n",
       "      <td>my dad passed away 6 years ago from a sudden s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582001</th>\n",
       "      <td>i see what you mean. the reason that i.do so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582210</th>\n",
       "      <td>i just had an season ending injury and have be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586025</th>\n",
       "      <td>this scares me, i feel like shock therapy will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588536</th>\n",
       "      <td>*he doesn't answer, still looking a little dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588643</th>\n",
       "      <td>it's his command seals coming in, sakura is de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589621</th>\n",
       "      <td>he had a cancerous growth in that leg.  there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589709</th>\n",
       "      <td>even for someone who doesn't struggle with dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590043</th>\n",
       "      <td>i live for time alone. my time. often times pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590531</th>\n",
       "      <td>my [website](http://www.theforgottenlair.net/)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590671</th>\n",
       "      <td>you won't believe me, because you'll never see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590837</th>\n",
       "      <td>(will do. i had to start rendering again becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595838</th>\n",
       "      <td>i don't know if it's the same for all psychs e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597827</th>\n",
       "      <td>&amp;gt; the arguments about an activist governmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598100</th>\n",
       "      <td>this is why i support gg. this is 99% of what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598246</th>\n",
       "      <td>that's the joke.\\n\\na lot of why they say gg w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598641</th>\n",
       "      <td>amen to your last statement. it takes a very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600729</th>\n",
       "      <td>when you're depressed, but you still have to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602069</th>\n",
       "      <td>on and off clinical depression sometimes lasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604710</th>\n",
       "      <td>can someone help me with foundation? i'm reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606971</th>\n",
       "      <td>***analyzing thugnuggets***\\n\\n* comments per ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607065</th>\n",
       "      <td>***\\n\\n**the self-made man**\\n\\na humanoid fig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612492</th>\n",
       "      <td>i actually believe that he's just really depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614150</th>\n",
       "      <td>also bitching about your depression and situat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614788</th>\n",
       "      <td>i spent all last year in near crippling depres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body\n",
       "1768    your tears will be fun on election night. i ho...\n",
       "2244    not op, but not everyone can work full time. w...\n",
       "4870    it feels like plastic but it could be impeccab...\n",
       "4902    you're being much more civil than i thought yo...\n",
       "6203          i've never gotten so depressed so quickly. \n",
       "7003    please, explain those reasons. i'm sure they'r...\n",
       "7898    she became extremely depressed upon entering t...\n",
       "8289    you can't easily make a gun in your house. dru...\n",
       "8758    &gt; the unfriending left rachael feeling depr...\n",
       "11036   well, depression is a mental disorder, so yes....\n",
       "11137   are you fucking retarded?? your telling someon...\n",
       "12688   i think i want to stay away from stuff like su...\n",
       "13104   mine started so early i can't actually remembe...\n",
       "13138   i am not sure what exactly do you mean by depr...\n",
       "14255   good thing it was anger that was the emotion h...\n",
       "14811   &gt; treat depression and mental illness\\n\\n&g...\n",
       "15074   most of the time i just wait until i stop feel...\n",
       "15940   i loved reading about you two's so's and lives...\n",
       "16518   i have generalised anxiety disorder with some ...\n",
       "16825   same thing goes about xmas.  i love the holida...\n",
       "17065                                crippling depression\n",
       "17314   that, on a level, we *know* there isn't anythi...\n",
       "17575   i've had a week of vacation so i've been brows...\n",
       "17927   she didn't know i was struggling with depressi...\n",
       "17991   i don't know how or why this got gilded, but i...\n",
       "18118   before: be sensual and flirty, not diving for ...\n",
       "18214   i make a lot of money. i know it sounds douche...\n",
       "18996   this is basically me. i'm not sure, i might ha...\n",
       "19110   as someone who keeps attempting it with clinic...\n",
       "19856   not at all! i appreciate the questions. i've b...\n",
       "...                                                   ...\n",
       "567914  you need to make a plan before you do lose you...\n",
       "567920  no being mean but..... i think you may need so...\n",
       "570169  a potentially very valuable asian american roo...\n",
       "570491  so testosterone depressed iq? maybe this shoul...\n",
       "573182  i must say that i'm glad about this. started h...\n",
       "580014  my dad passed away 6 years ago from a sudden s...\n",
       "582001  i see what you mean. the reason that i.do so m...\n",
       "582210  i just had an season ending injury and have be...\n",
       "586025  this scares me, i feel like shock therapy will...\n",
       "588536  *he doesn't answer, still looking a little dep...\n",
       "588643  it's his command seals coming in, sakura is de...\n",
       "589621  he had a cancerous growth in that leg.  there ...\n",
       "589709  even for someone who doesn't struggle with dep...\n",
       "590043  i live for time alone. my time. often times pe...\n",
       "590531  my [website](http://www.theforgottenlair.net/)...\n",
       "590671  you won't believe me, because you'll never see...\n",
       "590837  (will do. i had to start rendering again becau...\n",
       "595838  i don't know if it's the same for all psychs e...\n",
       "597827  &gt; the arguments about an activist governmen...\n",
       "598100  this is why i support gg. this is 99% of what ...\n",
       "598246  that's the joke.\\n\\na lot of why they say gg w...\n",
       "598641  amen to your last statement. it takes a very s...\n",
       "600729  when you're depressed, but you still have to g...\n",
       "602069  on and off clinical depression sometimes lasti...\n",
       "604710  can someone help me with foundation? i'm reall...\n",
       "606971  ***analyzing thugnuggets***\\n\\n* comments per ...\n",
       "607065  ***\\n\\n**the self-made man**\\n\\na humanoid fig...\n",
       "612492  i actually believe that he's just really depre...\n",
       "614150  also bitching about your depression and situat...\n",
       "614788  i spent all last year in near crippling depres...\n",
       "\n",
       "[843 rows x 1 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for comments that use depression\n",
    "df_2[(df_2['body'].str.contains('depressed') | df_2['body'].str.contains('depression'))]\n",
    "\n",
    "#drop them\n",
    "df_2.drop(df_2[(df_2.body.str.contains('depressed')) | (df_2.body.str.contains('depression'))].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613962"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recheck length\n",
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#column of 0's\n",
    "x = 0\n",
    "x = x * len(df_2)\n",
    "\n",
    "df_2['target'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#balance classes\n",
    "df_3 = df_2.sample(n=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311130, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine dfs\n",
    "df = pd.concat([df_3,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622260"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289723</th>\n",
       "      <td>&amp;gt;respecting authority\\n\\nfucking statist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302695</th>\n",
       "      <td>mate... you need to calm down. seriously. they...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111893</th>\n",
       "      <td>in lane just play a bully and focus her. i tre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117882</th>\n",
       "      <td>how about hockey? because i follow the rangers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282836</th>\n",
       "      <td>even the black cops are not exempt from racism...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body  target\n",
       "289723       &gt;respecting authority\\n\\nfucking statist        0\n",
       "302695  mate... you need to calm down. seriously. they...       0\n",
       "111893  in lane just play a bully and focus her. i tre...       0\n",
       "117882  how about hockey? because i follow the rangers...       0\n",
       "282836  even the black cops are not exempt from racism...       0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rt @ techreview : a neural network can detect depression and mania in bipolar subjects by analyzing how they hold and tap on their smartphone… '\n"
     ]
    }
   ],
   "source": [
    "#preprocess tweets\n",
    "example_text=\"\"\"'RT @techreview: A neural network can \n",
    "detect depression and mania in bipolar subjects \n",
    "by analyzing how they hold and tap on their smartphone…'\"\"\"\n",
    "\n",
    "# tokenize\n",
    "def tokenize_text(input_text):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "    input_text: a string representing an \n",
    "    individual review\n",
    "        \n",
    "    Returns:\n",
    "    input_token: a list containing stemmed \n",
    "    tokens, with punctutations removed, for \n",
    "    an individual review\n",
    "        \n",
    "    \"\"\"\n",
    "    input_tokens=[]\n",
    "        \n",
    "    # Split sentence\n",
    "    sents=sent_tokenize(input_text)\n",
    "            \n",
    "    # Split word\n",
    "    for sent in sents:\n",
    "        input_tokens+=TreebankWordTokenizer().tokenize(sent)\n",
    "        \n",
    "    return input_tokens\n",
    "\n",
    "\n",
    "# canonicalize\n",
    "def canonicalize_tokens(input_tokens):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    input_tokens: a list containing tokenized \n",
    "    tokens for an individual review\n",
    "    \n",
    "    Returns:\n",
    "    input_tokens: a list containing canonicalized \n",
    "    tokens for an individual review\n",
    "    \n",
    "    \"\"\"\n",
    "    input_tokens=utils.canonicalize_words(input_tokens)\n",
    "    return input_tokens\n",
    "\n",
    "\n",
    "# preprocessor \n",
    "def preprocessor(raw_text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    raw_text: a string representing an\n",
    "    individual review\n",
    "    \n",
    "    Returns:\n",
    "    preprocessed_text: a string representing \n",
    "    a preprocessed individual review\n",
    "    \n",
    "    \"\"\"\n",
    "    # tokenize\n",
    "    tokens=tokenize_text(raw_text)\n",
    "    \n",
    "    # canonicalize\n",
    "    canonical_tokens=canonicalize_tokens(tokens)\n",
    "    \n",
    "    # rejoin string\n",
    "    preprocessed_text=(\" \").join(canonical_tokens) \n",
    "    return preprocessed_text\n",
    "\n",
    "# example data\n",
    "#input_tokens=tokenize_text(example_text)\n",
    "#print(input_tokens)\n",
    "\n",
    "#canonical_tokens=canonicalize_tokens(input_tokens)\n",
    "#print(canonical_tokens)\n",
    "\n",
    "preprocessed_text=preprocessor(example_text) \n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sklearn stopwords: 318\n",
      "number of nltk stopwords: 179\n",
      "number of total stopwords: 388\n"
     ]
    }
   ],
   "source": [
    "# examine stopwords\n",
    "\n",
    "# sklearn stopwords (frozenset)\n",
    "sklearn_stopwords=stop_words.ENGLISH_STOP_WORDS\n",
    "print(\"number of sklearn stopwords: %d\" %(len(sklearn_stopwords)))\n",
    "#print(sklearn_stopwords)\n",
    "\n",
    "# nltk stopwords (list)\n",
    "nltk_stopwords=stopwords.words(\"english\")\n",
    "print(\"number of nltk stopwords: %d\" %(len(nltk_stopwords)))\n",
    "#print(nltk_stopwords)\n",
    "\n",
    "# combined sklearn, nltk, other stopwords (set)\n",
    "total_stopwords=set(list(sklearn_stopwords.difference(set(nltk_stopwords)))+nltk_stopwords)\n",
    "\n",
    "other_stopwords=[\"DG\", \"DGDG\", \"@\", \"rt\", \"'rt\", \"'\", \":\", \"depression\", \"depressed\", \"RT\"]\n",
    "for w in other_stopwords:\n",
    "    total_stopwords.add(w)\n",
    "    \n",
    "print(\"number of total stopwords: %d\" %(len(total_stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['techreview', 'neural', 'network', 'detect', 'mania', 'bipolar', 'subjects', 'analyzing', 'hold', 'tap', 'smartphone…']\n"
     ]
    }
   ],
   "source": [
    "#look at review w/o stop words\n",
    "new_review = []\n",
    "for i in preprocessed_text.split():\n",
    "    if i in total_stopwords:\n",
    "        continue\n",
    "    else:\n",
    "        new_review.append(i)\n",
    "        \n",
    "print(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, test set size: 497783, 124477\n",
      "\n",
      "example:\n",
      "body: oh man,\n",
      "i'm a big fan of you by bad religion\n",
      "\n",
      "label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#split into test, train before sampling to belance\n",
    "# using recoded labels\n",
    "#create train, test data\n",
    "df['is_train'] = np.random.uniform(0,1, len(df)) <= .8\n",
    "\n",
    "train_data, test_data = df[df['is_train'] == True], df[df['is_train'] == False]\n",
    "\n",
    "# examine train, test shapes\n",
    "print(\"train, test set size: %d, %d\" %(len(train_data), len(test_data)))\n",
    "print(\"\")\n",
    "\n",
    "# examine train set examples\n",
    "print(\"example:\")\n",
    "print(\"body: %s\" %(train_data.get_value(10,'body')))\n",
    "print(\"label: %s\" %(train_data.get_value(10,'target')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    248953\n",
       "0    248830\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check class balance\n",
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example:\n",
      "body: yea i don't really need her for my current team. i barely have servants that can really benefit from her.\n",
      "label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(\"example:\")\n",
    "print(\"body: %s\" %(train_data.get_value(32,'body')))\n",
    "print(\"label: %s\" %(train_data.get_value(32,'target')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['dg', 'dgdg', 'need', 'sha', 'wo'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#build tf-idf model\n",
    "vec=TfidfVectorizer(preprocessor=preprocessor, ngram_range=(1,3), stop_words=total_stopwords, max_features=10000)\n",
    "vec_train_data=vec.fit_transform(train_data['body']) \n",
    "vec_test_data=vec.transform(test_data['body']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benthompson/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression f1 score: 0.852\n",
      "logistic regression accuracy score: 0.852\n",
      "logistic regression confusion matrix:\n",
      "[[54567  7733]\n",
      " [10668 51509]]\n"
     ]
    }
   ],
   "source": [
    "# train Logistic Regression\n",
    "logit=LogisticRegression(penalty='l2')\n",
    "logit.fit(vec_train_data, train_data['target'])\n",
    "pred_labels=logit.predict(vec_test_data)\n",
    "    \n",
    "# assess model\n",
    "f1=f1_score(test_data['target'], pred_labels, average=\"weighted\") \n",
    "accuracy=accuracy_score(test_data['target'], pred_labels)\n",
    "confusion=confusion_matrix(test_data['target'], pred_labels)\n",
    "print(\"logistic regression f1 score: %.3f\" %(f1))\n",
    "print(\"logistic regression accuracy score: %.3f\" %(accuracy))\n",
    "print(\"logistic regression confusion matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights of words that predict depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>illness</th>\n",
       "      <td>4.845405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lonely</th>\n",
       "      <td>4.972430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medication</th>\n",
       "      <td>5.132374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling</th>\n",
       "      <td>5.180178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relatable</th>\n",
       "      <td>5.679322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depressive</th>\n",
       "      <td>5.791177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antidepressants</th>\n",
       "      <td>5.845671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psychiatrist</th>\n",
       "      <td>5.908124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happiness</th>\n",
       "      <td>5.969603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>6.215687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapists</th>\n",
       "      <td>6.423288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>6.652741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meds</th>\n",
       "      <td>6.782590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video games</th>\n",
       "      <td>6.987972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide</th>\n",
       "      <td>7.226767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapy</th>\n",
       "      <td>7.260391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anxiety</th>\n",
       "      <td>7.517250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relate</th>\n",
       "      <td>7.581352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicidal</th>\n",
       "      <td>7.852745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therapist</th>\n",
       "      <td>8.514391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Weights of words that predict depression\n",
       "illness                                          4.845405\n",
       "lonely                                           4.972430\n",
       "medication                                       5.132374\n",
       "feeling                                          5.180178\n",
       "relatable                                        5.679322\n",
       "depressive                                       5.791177\n",
       "antidepressants                                  5.845671\n",
       "psychiatrist                                     5.908124\n",
       "happiness                                        5.969603\n",
       "life                                             6.215687\n",
       "therapists                                       6.423288\n",
       "feel                                             6.652741\n",
       "meds                                             6.782590\n",
       "video games                                      6.987972\n",
       "suicide                                          7.226767\n",
       "therapy                                          7.260391\n",
       "anxiety                                          7.517250\n",
       "relate                                           7.581352\n",
       "suicidal                                         7.852745\n",
       "therapist                                        8.514391"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get top words\n",
    "#look at top 5 weights for each class\n",
    "#get coefficients for all features\n",
    "coef_sq = logit.coef_\n",
    "\n",
    "#get index of top 5 absolute values for each class\n",
    "weight_indx = np.argsort(coef_sq)[:, -20:]\n",
    "\n",
    "#flatten so can use to look up wieghts\n",
    "weight_indx = weight_indx.flatten()\n",
    "\n",
    "#get coefficients based on index\n",
    "weights = coef_sq[:, weight_indx]\n",
    " \n",
    "#get words that match weights based on index\n",
    "vocab = np.array(vec.get_feature_names())[weight_indx]\n",
    "\n",
    "# make table\n",
    "df = pd.DataFrame({'Weights of words that predict depression': weights[0]}\n",
    "                  , index=vocab)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of class 0 and 1:  [[ 0.18187016  0.81812984]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights of words in sample Journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>store</th>\n",
       "      <td>-1.041158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure going</th>\n",
       "      <td>-0.405577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weird</th>\n",
       "      <td>0.312819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strange</th>\n",
       "      <td>0.366745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>0.545399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>0.555881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makes</th>\n",
       "      <td>0.574439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>0.832820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>1.246184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>1.419033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makes feel</th>\n",
       "      <td>1.733432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>6.652741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Weights of words in sample Journal\n",
       "store                                 -1.041158\n",
       "sure going                            -0.405577\n",
       "weird                                  0.312819\n",
       "strange                                0.366745\n",
       "going                                  0.545399\n",
       "sure                                   0.555881\n",
       "makes                                  0.574439\n",
       "wonderful                              0.832820\n",
       "interaction                            1.246184\n",
       "today                                  1.419033\n",
       "makes feel                             1.733432\n",
       "feel                                   6.652741"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try to make up an example journal\n",
    "journal = \"\"\"Today was wonderful. I had a strange interaction at the store. \n",
    "The cashier seemed irratated. I'm not sure what's going on but it makes me feel weird\"\"\"\n",
    "\n",
    "#score test journal\n",
    "vec_test_example=vec.transform([journal]) \n",
    "print(\"probability of class 0 and 1: \",logit.predict_proba(vec_test_example))\n",
    "\n",
    "#get words and weights from test journal\n",
    "word_idx = np.nonzero(vec_test_example)[1]\n",
    "vocab = np.array(vec.get_feature_names())[word_idx]\n",
    "weights = coef_sq[:, word_idx]\n",
    "df = pd.DataFrame({'Weights of words in sample Journal': weights[0]}\n",
    "                  , index=vocab)\n",
    "df.sort_values(by='Weights of words in sample Journal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_exported_model']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export tfidf model\n",
    "tfidf_file = 'tfidf_exported_model'\n",
    "joblib.dump(vec, tfidf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export logistic regression\n",
    "logistic_regression_file = 'logistic_regression_model'\n",
    "joblib.dump(logit, logistic_regression_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of class 0 and 1:  [[ 0.43736519  0.56263481]]\n"
     ]
    }
   ],
   "source": [
    "#test out exported models against prev sample journal\n",
    "loaded_tfidf = joblib.load('tfidf_exported_model')\n",
    "loaded_lr = joblib.load('logistic_regression_model')\n",
    "\n",
    "#score test journal\n",
    "export_test_example=loaded_tfidf.transform([journal]) \n",
    "print(\"probability of class 0 and 1: \",loaded_lr.predict_proba(export_test_example))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras and Tensor Flow",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
